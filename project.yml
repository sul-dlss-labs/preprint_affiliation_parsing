title: Affiliation Extraction and Parsing from OpenALEX Preprints

vars:
  embedding: "tok2vec" # tok2vec, transformer
  config_file: "config_${embedding}.cfg"
  transformer_model_name: "roberta-base" # any huggingface model name
  gpu_id: 0

directories:
  - assets
  - training
  - results

assets:
  - dest: "assets/preprints.csv"
    git:
      repo: https://github.com/sul-dlss-labs/preprints-evaluation-dataset.git
      branch: main
      path: records.csv
    checksum: 68138588160e22998f6e6921f4e705d8 # md5
    description: List of preprint documents in the training dataset

workflows:
  prepare:
    - preprints:download
    - preprints:clean
    - dataset:textcat:create

commands:
  - name: dependencies:install
    help: Install dependencies
    script:
      - pip install -r requirements.txt
      - python -m spacy download en_core_web_lg # for suggestion & segmentation
      - /bin/bash -c "if [[ $(arch) == 'arm64' ]]; then pip install thinc-apple-ops; fi" # for M-series macs

  - name: preprints:download
    help: Download preprint PDFs and metadata (**Needs Stanford VPN**)
    outputs:
      - assets/preprints/pdf
    script:
      - python scripts/download_preprints.py assets/preprints.csv assets/preprints/pdf
      - python scripts/download_metadata.py assets/preprints.csv assets/preprints/json

  - name: preprints:clean
    help: Extract plain text from preprint PDFs
    deps:
      - assets/preprints/pdf
    outputs:
      - assets/preprints/txt
    script:
      - python scripts/clean_preprints.py assets/preprints/pdf assets/preprints/txt

  - name: dataset:textcat:create
    help: Create a dataset for annotating text categorization training data
    deps:
      - assets/preprints/txt
    outputs:
      - assets/preprints_textcat.jsonl
    script:
      - python scripts/create_textcat_dataset.py assets/preprints_textcat.jsonl

  - name: annotate:textcat
    help: Annotate binary training data for text categorization
    deps:
      - assets/preprints_textcat.jsonl
    script:
      - python -m prodigy textcat.manual preprints_textcat assets/preprints_textcat.jsonl --label AFFILIATION

  - name: dataset:ner:create
    help: Create a dataset for annotating NER data
    deps:
      - assets/preprints/txt
    outputs:
      - assets/preprints.jsonl
    script:
      - python scripts/create_ner_dataset.py assets/preprints.jsonl

  - name: annotate:ner
    help: Annotate training data for NER by correcting and updating an existing model
    deps:
      - assets/preprints.jsonl
    script:
      - python -m prodigy ner.correct preprints_ner en_core_web_trf assets/preprints.jsonl --label PERSON,ORG,GPE --update

  - name: train_textcat
    help: Train spaCy text categorization pipeline for affiliation extraction
    deps:
      - "configs/textcat/${vars.config_file}"
      - corpus/textcat/train.spacy
      - corpus/textcat/dev.spacy
    script:
      - "python -m spacy train configs/textcat/${vars.config_file} --output training/textcat --gpu-id ${vars.gpu_id} --vars.transformer_model_name ${vars.transformer_model_name}"

  - name: train_ner
    help: Train spaCy NER pipeline for affiliation parsing
    deps:
      - "configs/ner/${vars.config_file}"
      - corpus/ner/train.spacy
      - corpus/ner/dev.spacy
    script:
      - "python -m spacy train configs/ner/${vars.config_file} --output training/ner --gpu-id ${vars.gpu_id} --vars.transformer_model_name ${vars.transformer_model_name}"
