{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline evaluation\n",
    "\n",
    "This notebook is used to evaluate the entire pipeline. It compares the predictions of the pipeline with the ground truth author and affiliation data, along with predictions made using other strategies.\n",
    "\n",
    "Ground truth authors and affiliations were cataloged by hand using SHROOM, and are downloaded as Cocina from SDR by the `preprints:download` task (see README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/budak/.pyenv/versions/3.12.2/envs/ezdeposit/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/budak/.pyenv/versions/3.12.2/envs/ezdeposit/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/budak/.pyenv/versions/3.12.2/envs/ezdeposit/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/budak/.pyenv/versions/3.12.2/envs/ezdeposit/lib/python3.12/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# set up project root path for imports\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "PROJECT_ROOT = pathlib.Path(root)\n",
    "\n",
    "# make scripts in scripts/ importable and import the analysis pipeline\n",
    "sys.path.insert(1, str(PROJECT_ROOT / 'scripts'))\n",
    "from api import analyze_pdf\n",
    "from utils import get_cocina_affiliations\n",
    "\n",
    "# Load the models\n",
    "import spacy\n",
    "ner = spacy.load(\"en_core_web_trf\")\n",
    "ner.disable_pipes(\"parser\")\n",
    "textcat = spacy.load(PROJECT_ROOT / 'training' / 'textcat' / 'model-best')\n",
    "\n",
    "# convenience function for fetching preprint text\n",
    "def get_preprint_text(preprint_id):\n",
    "    fp = PROJECT_ROOT / \"assets\" / \"preprints\" / \"txt\" / f\"{preprint_id}.txt\"\n",
    "    try:\n",
    "        return fp.read_text(encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Preprint text not found for {preprint_id}\")\n",
    "        return \"\"\n",
    "\n",
    "# convenience function for fetching gold affiliations from cocina\n",
    "import json\n",
    "def get_gold_affiliations(preprint_id):\n",
    "    fp = PROJECT_ROOT / \"assets\" / \"preprints\" / \"json\" / f\"{preprint_id}.json\"\n",
    "    try:\n",
    "        json_str = fp.read_text(encoding='utf-8')\n",
    "        cocina = json.loads(json_str)\n",
    "        return get_cocina_affiliations(cocina)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Cocina data not found for {preprint_id}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data table with columns for gold and predicted affiliations\n",
    "import pandas as pd\n",
    "preprints = pd.read_csv(PROJECT_ROOT / 'assets' / 'preprints.csv')\n",
    "preprints['text'] = ''\n",
    "preprints['pred'] = ''\n",
    "preprints['gold'] = ''\n",
    "\n",
    "# add the full text and gold affiliations to the data table\n",
    "for i, row in preprints.iterrows():\n",
    "    openalex_url = row['OpenAlex ID']\n",
    "    preprint_id = openalex_url.split('/')[-1]\n",
    "    preprint_text = get_preprint_text(preprint_id)\n",
    "    preprint_file = PROJECT_ROOT / \"assets\" / \"preprints\" / \"pdf\" / f\"{preprint_id}.pdf\"\n",
    "    preprints.at[i, 'text'] = preprint_text\n",
    "    preprints.at[i, 'gold'] = get_gold_affiliations(preprint_id)\n",
    "\n",
    "# limit to only rows where we have gold affiliations\n",
    "preprints = preprints[preprints['gold'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m preprints\u001b[38;5;241m.\u001b[39miterrows():    \n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m preprint_file\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m       preprints\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m analyze_pdf(f, ner, textcat)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# display HTML\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n",
      "File \u001b[0;32m~/Developer/preprint_affiliation_parsing/scripts/api.py:39\u001b[0m, in \u001b[0;36manalyze_pdf\u001b[0;34m(file, textcat, ner, threshold)\u001b[0m\n\u001b[1;32m     37\u001b[0m pdf_struct \u001b[38;5;241m=\u001b[39m pdf_bytes_to_struct(pdf_bytes)\n\u001b[1;32m     38\u001b[0m pdf_text \u001b[38;5;241m=\u001b[39m text_from_struct(pdf_struct)\n\u001b[0;32m---> 39\u001b[0m affiliation_text \u001b[38;5;241m=\u001b[39m \u001b[43mget_affiliation_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m doc \u001b[38;5;241m=\u001b[39m ner(affiliation_text)\n\u001b[1;32m     41\u001b[0m doc \u001b[38;5;241m=\u001b[39m set_affiliation_ents(ner, doc)\n",
      "File \u001b[0;32m~/Developer/preprint_affiliation_parsing/scripts/utils.py:102\u001b[0m, in \u001b[0;36mget_affiliation_text\u001b[0;34m(text, nlp, threshold)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_affiliation_text\u001b[39m(\n\u001b[1;32m     97\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,  \u001b[38;5;66;03m# The text to search for affiliations\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     nlp: spacy\u001b[38;5;241m.\u001b[39mlanguage\u001b[38;5;241m.\u001b[39mLanguage,  \u001b[38;5;66;03m# The spaCy model to use for text classification\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     threshold: \u001b[38;5;28mfloat\u001b[39m,  \u001b[38;5;66;03m# The minimum probability for a block to be considered an affiliation\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m--> 102\u001b[0m         [block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_affiliation_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    103\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/preprint_affiliation_parsing/scripts/utils.py:120\u001b[0m, in \u001b[0;36mget_affiliation_blocks\u001b[0;34m(text, nlp, threshold)\u001b[0m\n\u001b[1;32m    118\u001b[0m block \u001b[38;5;241m=\u001b[39m all_blocks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_affiliation\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 120\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mall_blocks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# 4. Get all affiliations on that page\u001b[39;00m\n\u001b[1;32m    123\u001b[0m first_affiliation_page \u001b[38;5;241m=\u001b[39m block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# add predicted affiliations for each preprint\n",
    "for i, row in preprints.iterrows():    \n",
    "  with preprint_file.open(mode=\"rb\") as f:\n",
    "      preprints.at[i, 'pred'] = await analyze_pdf(f, ner, textcat)\n",
    "\n",
    "# display HTML\n",
    "from IPython.display import display\n",
    "display(preprints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezdeposit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
