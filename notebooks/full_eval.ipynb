{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline evaluation\n",
    "\n",
    "This notebook is used to evaluate the entire pipeline. It compares the predictions of the pipeline with the ground truth author and affiliation data, along with predictions made using other strategies.\n",
    "\n",
    "Ground truth authors and affiliations were cataloged by hand using SHROOM, and are downloaded as Cocina from SDR by the `preprints:download` task (see README.md). This needs to be run prior to running this notebook.\n",
    "\n",
    "Article plain texts are extracted from the PDFs using the `preprints:clean` task (see README.md). This also needs to be run prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/budak/.pyenv/versions/3.12.2/envs/ezdeposit/lib/python3.12/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# set up project root path for imports\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "PROJECT_ROOT = pathlib.Path(root)\n",
    "\n",
    "# make scripts in scripts/ importable and import util functions\n",
    "sys.path.insert(1, str(PROJECT_ROOT / 'scripts'))\n",
    "from notebook_utils import get_preprint_text, get_gold_affiliations, load_predictions\n",
    "\n",
    "# Load the models\n",
    "import spacy\n",
    "ner = spacy.load(\"en_core_web_trf\")\n",
    "ner.disable_pipes(\"parser\")\n",
    "textcat = spacy.load(PROJECT_ROOT / 'training' / 'textcat' / 'model-best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprint text not found for W3091005730\n",
      "Preprint text not found for W3185060415\n"
     ]
    }
   ],
   "source": [
    "# set up data table with columns for gold and predicted affiliations\n",
    "import pandas as pd\n",
    "preprints = pd.read_csv(PROJECT_ROOT / 'assets' / 'preprints.csv')\n",
    "preprints['gold'] = ''\n",
    "\n",
    "# add the full text and gold affiliations to the data table\n",
    "for i, row in preprints.iterrows():\n",
    "    preprint_id = row['OpenAlex ID']\n",
    "    preprint_text = get_preprint_text(preprint_id)\n",
    "    preprint_file = PROJECT_ROOT / \"assets\" / \"preprints\" / \"pdf\" / f\"{preprint_id}.pdf\"\n",
    "    preprints.at[i, 'gold'] = get_gold_affiliations(preprint_id)\n",
    "    preprints.at[i, 'text'] = preprint_text\n",
    "    \n",
    "\n",
    "# keep only the columns we need\n",
    "preprints = preprints[['OpenAlex ID', 'DRUID', 'text', 'gold']]\n",
    "\n",
    "# limit to only rows where we have gold affiliations\n",
    "preprints = preprints[preprints['gold'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No predictions found, running prediction for all preprints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3cc34229134c8f8d37d4f73b897653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing W3178821884: No affiliations found in document.\n",
      "Error analyzing W3116436840: No affiliations found in document.\n",
      "Error analyzing W4226047880: No affiliations found in document.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_affiliation_dict, analyze_pdf_text\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# set this and run cell to force re-running predictions\n",
    "FORCE_RERUN = True\n",
    "\n",
    "# add a column for predictions\n",
    "preprints['pred'] = ''\n",
    "\n",
    "# if we don't have any saved predictions, run prediction for every preprint\n",
    "predictions = load_predictions()\n",
    "if not predictions or FORCE_RERUN:\n",
    "    print(\"No predictions found, running prediction for all preprints\")\n",
    "    for i, row in tqdm(preprints.iterrows(), total=len(preprints), desc=\"Predicting\"):\n",
    "        preprint_id = row['OpenAlex ID']\n",
    "        preprint_file = PROJECT_ROOT / \"assets\" / \"preprints\" / \"txt\" / f\"{preprint_id}.txt\"\n",
    "        pdf_text = preprint_file.read_text(encoding='utf-8')\n",
    "        try:\n",
    "            result = analyze_pdf_text(pdf_text, textcat, ner)\n",
    "            affiliations = get_affiliation_dict(result)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error analyzing {preprint_id}: {e}\")\n",
    "            affiliations = {}\n",
    "        with (results_path / f\"{preprint_id}.json\").open(mode=\"w\") as f:\n",
    "            json.dump(affiliations, f)\n",
    "    predictions = load_predictions()\n",
    "else:\n",
    "    print(\"Using saved predictions\")\n",
    "\n",
    "# set predictions for each preprint in the data table\n",
    "for i, row in preprints.iterrows():\n",
    "    preprint_id = row['OpenAlex ID']\n",
    "    if preprint_id in predictions:\n",
    "        preprints.at[i, 'pred'] = predictions[preprint_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTHORS\n",
      "  avg accuracy\t\t 49.0%\n",
      "  count of 100%\t\t 23\n",
      "  count of 1-99%\t 38\n",
      "  count of 0%\t\t 37\n"
     ]
    }
   ],
   "source": [
    "# calculate some accuracy statistics for authors\n",
    "for i, row in preprints.iterrows():\n",
    "    gold = row.gold\n",
    "    pred = row.pred\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for author in gold:\n",
    "        total += 1\n",
    "        if author in pred:\n",
    "            correct += 1\n",
    "    preprints.at[i, 'authors_accuracy'] = correct / total if total > 0 else (1 if correct == 0 else 0)\n",
    "\n",
    "author_acc_mean = preprints['authors_accuracy'].mean()\n",
    "author_acc_1 = preprints[preprints['authors_accuracy'] == 1]\n",
    "author_acc_0 = preprints[preprints['authors_accuracy'] == 0]\n",
    "author_acc_mid = preprints[(preprints['authors_accuracy'] > 0) & (preprints['authors_accuracy'] < 1)]\n",
    "\n",
    "# get some author statistics\n",
    "print(\"AUTHORS\")\n",
    "print(\"  avg accuracy\\t\\t\", f\"{author_acc_mean.round(2) * 100}%\")\n",
    "print(\"  count of 100%\\t\\t\", len(author_acc_1))\n",
    "print(\"  count of 1-99%\\t\", len(author_acc_mid))\n",
    "print(\"  count of 0%\\t\\t\", len(author_acc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFFILIATIONS\n",
      "  avg accuracy\t\t 5.0%\n",
      "  count of 100%\t\t 0\n",
      "  count of 1-99%\t 13\n",
      "  count of 0%\t\t 85\n"
     ]
    }
   ],
   "source": [
    "# calculate some accuracy statistics for affiliations\n",
    "for i, row in preprints.iterrows():\n",
    "    gold = row.gold\n",
    "    pred = row.pred\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for author in gold:\n",
    "        for affiliation in gold[author]:\n",
    "            total += 1\n",
    "            if author in pred and affiliation in pred[author]:\n",
    "                correct += 1\n",
    "    preprints.at[i, 'affiliations_accuracy'] = correct / total if total > 0 else (1 if correct == 0 else 0)\n",
    "\n",
    "affil_acc_mean = preprints['affiliations_accuracy'].mean()\n",
    "affil_acc_1 = preprints[preprints['affiliations_accuracy'] == 1]\n",
    "affil_acc_0 = preprints[preprints['affiliations_accuracy'] == 0]\n",
    "affil_acc_mid = preprints[(preprints['affiliations_accuracy'] > 0) & (preprints['affiliations_accuracy'] < 1)]\n",
    "\n",
    "# get some affiliation statistics\n",
    "print(\"\\nAFFILIATIONS\")\n",
    "print(\"  avg accuracy\\t\\t\", f\"{affil_acc_mean.round(2) * 100}%\")\n",
    "print(\"  count of 100%\\t\\t\", len(affil_acc_1))\n",
    "print(\"  count of 1-99%\\t\", len(affil_acc_mid))\n",
    "print(\"  count of 0%\\t\\t\", len(affil_acc_0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezdeposit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
